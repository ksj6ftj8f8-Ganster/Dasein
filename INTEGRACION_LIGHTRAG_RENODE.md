# üåê ESTRATEGIA DE INTEGRACI√ìN: LightRAG + Renode Entity
**Documento:** Plan de Integraci√≥n | **Versi√≥n:** 1.0 | **Fecha:** 2024

---

## üìä RESUMEN EJECUTIVO

### Ecosistema Actual
- **LightRAG:** Framework RAG (Retrieval-Augmented Generation) con grafos de conocimiento
- **Renode Entity:** Sistema de simulaci√≥n de hardware con an√°lisis de side-channel (72 dimensiones)
- **Oportunidad:** Integrar datos de side-channel en la base de conocimiento de LightRAG

### Caso de Uso Propuesto
Crear un RAG que comprenda patrones de consumo de energ√≠a y comportamiento de seguridad en sistemas embebidos, permitiendo:
- Consultas: "¬øCu√°les son las instrucciones que causan m√°ximo consumo de energ√≠a?"
- An√°lisis: "Predecir leaks de seguridad basado en lado-channel"
- Optimizaci√≥n: "Qu√© operaciones criptogr√°ficas son menos detectables?"

---

## üèóÔ∏è ARQUITECTURA DE INTEGRACI√ìN

### Opci√≥n 1: Pipeline Directo (Recomendada)
```
Renode Simulator
    ‚Üì (CSV: measurements.csv)
Recolector de Datos
    ‚Üì (72-dimensi√≥n)
LightRAG Graph Builder
    ‚Üì
Grafo de Conocimiento
    ‚îú‚îÄ Nodos: Instructions, Operands, Energy Levels
    ‚îú‚îÄ Edges: Consumes, Triggers, Precedes
    ‚îî‚îÄ Propiedades: CPA Correlation, TVLA p-value
    ‚Üì
RAG Query Engine
    ‚Üì
An√°lisis + Predicci√≥n
```

### Opci√≥n 2: Almacenamiento Paralelo
```
Renode ‚Üí Time-Series DB (InfluxDB)
       ‚Üí Graph DB (Neo4j) para patrones
       ‚Üí Vector Store (Milvus) para busqueda sem√°ntica
       ‚Üí LightRAG Knowledge Graph
```

### Opci√≥n 3: An√°lisis Post-Hoc
```
Renode Simulator (genera reports/)
    ‚Üì (JSON: measurements.json)
An√°lisis Offline
    ‚Üì
LightRAG Ingesta Batch
    ‚Üì
Actualizar grafo cada semana
```

---

## üìù IMPLEMENTACI√ìN T√âCNICA

### Paso 1: Adaptador de Datos Renode ‚Üí LightRAG

**Archivo:** `/workspaces/Dasein/lightrag/adapters/renode_adapter.py`

```python
#!/usr/bin/env python3
"""
Adaptador para integrar datos de Renode Entity en LightRAG
"""

import json
import csv
from pathlib import Path
from typing import Dict, List, Any
from dataclasses import dataclass

@dataclass
class MeasurementSample:
    """Una muestra de medici√≥n del sistema Renode"""
    timestamp: float
    temperature: float
    energy: float
    latency: float
    dimensions: List[float]  # 72-dimensional vector
    instruction_id: str  # Hash de instrucci√≥n ejecutada
    
    @classmethod
    def from_renode_csv(cls, row: Dict[str, str]) -> "MeasurementSample":
        """Parsear fila CSV de Renode"""
        return cls(
            timestamp=float(row['timestamp']),
            temperature=float(row['temperature']),
            energy=float(row['energy']),
            latency=float(row['latency']),
            dimensions=[float(row[f'dim_{i}']) for i in range(72)],
            instruction_id=row.get('instruction_id', 'unknown')
        )

class RenodeToLightRAGAdapter:
    """Adaptador para convertir datos Renode ‚Üí LightRAG entities"""
    
    def __init__(self, lightrag_instance):
        self.rag = lightrag_instance
        
    async def ingest_measurements(self, csv_file: Path) -> Dict[str, Any]:
        """
        Ingestar archivo CSV de Renode en LightRAG
        
        Args:
            csv_file: Ruta a measurements.csv de Renode
            
        Returns:
            Dict con estad√≠sticas de ingesta
        """
        measurements = []
        
        # Leer CSV
        with open(csv_file, 'r') as f:
            reader = csv.DictReader(f)
            for row in reader:
                measurements.append(MeasurementSample.from_renode_csv(row))
        
        # Agrupar por instrucci√≥n
        by_instruction = {}
        for m in measurements:
            if m.instruction_id not in by_instruction:
                by_instruction[m.instruction_id] = []
            by_instruction[m.instruction_id].append(m)
        
        # Crear entidades en LightRAG
        stats = {
            "total_samples": len(measurements),
            "unique_instructions": len(by_instruction),
            "entities_created": 0,
            "relationships_created": 0
        }
        
        for instr_id, samples in by_instruction.items():
            # Estad√≠sticas por instrucci√≥n
            avg_energy = sum(s.energy for s in samples) / len(samples)
            avg_temp = sum(s.temperature for s in samples) / len(samples)
            max_latency = max(s.latency for s in samples)
            
            # Crear entidad de instrucci√≥n
            entity_text = f"""
            Instruction: {instr_id}
            Average Energy: {avg_energy:.6f} J
            Average Temperature: {avg_temp:.2f} ¬∞C
            Max Latency: {max_latency:.3f} ¬µs
            Sample Count: {len(samples)}
            """
            
            # Ingestar en LightRAG
            await self.rag.ainsert(entity_text)
            stats["entities_created"] += 1
            
            # Crear relaciones entre instrucciones correlacionadas
            for other_id, other_samples in by_instruction.items():
                if other_id != instr_id:
                    correlation = self._calculate_correlation(samples, other_samples)
                    if correlation > 0.7:  # Solo si correlaci√≥n es fuerte
                        relationship_text = f"""
                        {instr_id} CORRELATES_WITH {other_id}
                        Correlation: {correlation:.3f}
                        Both instructions share similar energy patterns
                        """
                        await self.rag.ainsert(relationship_text)
                        stats["relationships_created"] += 1
        
        return stats
    
    def _calculate_correlation(self, samples1: List[MeasurementSample], 
                              samples2: List[MeasurementSample]) -> float:
        """Calcular correlaci√≥n de energ√≠a entre dos conjuntos"""
        import numpy as np
        
        # Alinear muestras por timestamp
        energy1 = np.array([s.energy for s in samples1[:100]])  # Primeras 100
        energy2 = np.array([s.energy for s in samples2[:100]])
        
        if len(energy1) == 0 or len(energy2) == 0:
            return 0.0
        
        correlation_matrix = np.corrcoef(energy1, energy2)
        return float(correlation_matrix[0, 1])
    
    async def query_energy_patterns(self, query: str) -> str:
        """Consultar patrones de energ√≠a via LightRAG"""
        return await self.rag.aquery(query)

# Ejemplo de uso
async def main():
    from lightrag import LightRAG
    
    # Inicializar LightRAG
    rag = LightRAG(
        working_dir="./rag_storage/renode_analysis"
    )
    
    # Crear adaptador
    adapter = RenodeToLightRAGAdapter(rag)
    
    # Ingestar datos
    csv_path = Path("./renode_entity/reports/measurements.csv")
    stats = await adapter.ingest_measurements(csv_path)
    
    print(f"Ingesta completada:")
    print(f"  - Muestras: {stats['total_samples']}")
    print(f"  - Instrucciones √∫nicas: {stats['unique_instructions']}")
    print(f"  - Entidades creadas: {stats['entities_created']}")
    print(f"  - Relaciones creadas: {stats['relationships_created']}")
    
    # Consultar
    result = await adapter.query_energy_patterns(
        "¬øCu√°l es la instrucci√≥n que consume m√°s energ√≠a?"
    )
    print(f"\nResultado de consulta:\n{result}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
```

### Paso 2: Configuraci√≥n de LightRAG para Datos Renode

**Archivo:** `/workspaces/Dasein/config_renode_rag.json`

```json
{
  "rag_config": {
    "mode": "hybrid",
    "entity_extraction": {
      "top_k": 10,
      "relation_extraction": true
    },
    "vector_store": "milvus",
    "graph_store": "neo4j",
    "llm": {
      "model": "gpt-4",
      "temperature": 0.2,
      "context_window": 4000
    }
  },
  
  "renode_integration": {
    "data_source": "./renode_entity/reports/measurements.csv",
    "update_frequency": "daily",
    "entity_types": {
      "Instruction": {
        "properties": ["id", "avg_energy", "avg_temp", "max_latency"]
      },
      "EnergyPattern": {
        "properties": ["pattern_type", "correlation", "instructions"]
      },
      "SecurityVulnerability": {
        "properties": ["cpa_value", "tvla_p_value", "severity"]
      }
    },
    "relationships": {
      "CORRELATES_WITH": "Energ√≠a correlacionada",
      "TRIGGERS": "Provoca patr√≥n de energ√≠a",
      "LEAKS_INFORMATION": "Fuga de informaci√≥n potencial"
    }
  },
  
  "queries": [
    "¬øCu√°les son los patrones de energ√≠a m√°s comunes?",
    "¬øQu√© operaciones son potencialmente detectables por side-channel?",
    "¬øCu√°l es la correlaci√≥n entre instrucciones y consumo de energ√≠a?",
    "¬øC√≥mo se pueden ocultar las firmas de energ√≠a?"
  ]
}
```

### Paso 3: Extracci√≥n de Patrones de Seguridad

**Archivo:** `/workspaces/Dasein/lightrag/security_patterns/side_channel_extractor.py`

```python
#!/usr/bin/env python3
"""
Extractor de patrones de seguridad desde Renode Entity
"""

import json
import numpy as np
from typing import Dict, List, Tuple
from dataclasses import dataclass

@dataclass
class SecurityPattern:
    """Patr√≥n de seguridad detectado"""
    name: str
    severity: str  # "critical", "high", "medium", "low"
    cpa_correlation: float
    tvla_p_value: float
    affected_instructions: List[str]
    mitigation: str

class SideChannelExtractor:
    """Extraer patrones de side-channel del an√°lisis Renode"""
    
    def __init__(self, measurements_json: str):
        with open(measurements_json, 'r') as f:
            self.data = json.load(f)
    
    def extract_patterns(self) -> List[SecurityPattern]:
        """Extraer patrones de seguridad"""
        patterns = []
        
        # Analizar correlaci√≥n CPA
        cpa_corr = self.data.get('cpa_correlation', 0)
        if cpa_corr > 0.9:
            patterns.append(SecurityPattern(
                name="Muy fuerte fugas por an√°lisis de potencia (CPA)",
                severity="critical",
                cpa_correlation=cpa_corr,
                tvla_p_value=self.data.get('tvla_p_value', 0),
                affected_instructions=self._get_high_leak_instructions(),
                mitigation="Implementar masking criptogr√°fico o shuffling de instrucciones"
            ))
        elif cpa_corr > 0.7:
            patterns.append(SecurityPattern(
                name="Fugas significativas por an√°lisis de potencia",
                severity="high",
                cpa_correlation=cpa_corr,
                tvla_p_value=self.data.get('tvla_p_value', 0),
                affected_instructions=self._get_high_leak_instructions(),
                mitigation="Revisar implementaci√≥n criptogr√°fica, considerar constant-time"
            ))
        
        # Analizar TVLA
        tvla_p = self.data.get('tvla_p_value', 1)
        if tvla_p < 0.0001:
            patterns.append(SecurityPattern(
                name="Detecci√≥n estad√≠stica de fugas (TVLA extrema)",
                severity="critical",
                cpa_correlation=0,
                tvla_p_value=tvla_p,
                affected_instructions=self._get_all_instructions(),
                mitigation="Implementar contra-medidas a nivel de arquitectura (constant time)"
            ))
        
        return patterns
    
    def _get_high_leak_instructions(self) -> List[str]:
        """Obtener instrucciones con mayor fuga de informaci√≥n"""
        # Implementaci√≥n simplificada
        return ["MUL", "LDRB", "STRB", "CMP"]
    
    def _get_all_instructions(self) -> List[str]:
        return ["ADD", "SUB", "MUL", "DIV", "LDRB", "STRB", "CMP", "BNE"]

# Ejemplo
extractor = SideChannelExtractor("./renode_entity/reports/measurements.json")
patterns = extractor.extract_patterns()

for pattern in patterns:
    print(f"üö® {pattern.name}")
    print(f"   Severidad: {pattern.severity}")
    print(f"   CPA Correlation: {pattern.cpa_correlation:.3f}")
    print(f"   TVLA p-value: {pattern.tvla_p_value}")
    print(f"   Instrucciones afectadas: {pattern.affected_instructions}")
    print(f"   Mitigaci√≥n: {pattern.mitigation}\n")
```

---

## üîÑ FLUJO DE INGESTA

```
1. Ejecutar Renode Entity
   ‚îî‚îÄ python3 renode_script.py --duration 60

2. Generar CSV de mediciones
   ‚îî‚îÄ renode_entity/reports/measurements.csv

3. Ejecutar Adaptador
   ‚îî‚îÄ python3 renode_adapter.py

4. LightRAG Ingesta
   ‚îú‚îÄ Procesar CSV
   ‚îú‚îÄ Extraer entidades
   ‚îú‚îÄ Crear relaciones
   ‚îî‚îÄ Actualizar grafo

5. An√°lisis de Seguridad
   ‚îú‚îÄ Ejecutar side_channel_extractor.py
   ‚îú‚îÄ Identificar patrones
   ‚îú‚îÄ Clasificar severidad
   ‚îî‚îÄ Generar reportes

6. Consultas RAG
   ‚îú‚îÄ "¬øCu√°les instrucciones son riesgosas?"
   ‚îú‚îÄ "¬øC√≥mo mitigar side-channels?"
   ‚îî‚îÄ "¬øCu√°l es el patr√≥n de energ√≠a t√≠pico?"
```

---

## üéØ CASOS DE USO

### Caso 1: An√°lisis de Vulnerabilidades
```
Entrada: C√≥digo criptogr√°fico en C
Proceso:
  1. Compilar y ejecutar en Renode
  2. Recolectar mediciones (72-D)
  3. Ejecutar CPA/TVLA
  4. Ingestar en LightRAG
  5. Consultar: "¬øHay vulnerabilidades de side-channel?"
Salida: Reporte de severidad + recomendaciones
```

### Caso 2: Optimizaci√≥n de Seguridad
```
Entrada: M√∫ltiples implementaciones de AES
Proceso:
  1. Ejecutar cada una en Renode
  2. Comparar correlaciones CPA
  3. Crear grafo de "implementaciones vs severidad"
  4. Consultar: "¬øCu√°l implementaci√≥n es m√°s segura?"
Salida: Ranking de seguridad con justificaci√≥n
```

### Caso 3: Predicci√≥n de Riesgos
```
Entrada: Nueva arquitectura de CPU
Proceso:
  1. Simular en Renode con nueva configuraci√≥n
  2. Recolectar datos de rendimiento
  3. Ingestar patrones en LightRAG
  4. Consultar: "¬øCu√°les son los riesgos potenciales?"
Salida: An√°lisis predictivo de vulnerabilidades
```

---

## üìä ESTRUCTURA DE GRAFO

### Ejemplo de Grafo Construido
```
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Instruction    ‚îÇ
    ‚îÇ    "MUL"        ‚îÇ
    ‚îÇ energy: 0.045J  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ          ‚îÇ
    [CPA: 0.92]  [TVLA: 0.0001]
        ‚îÇ          ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇPattern‚îÇ    ‚îÇPattern‚îÇ
    ‚îÇ CPA   ‚îÇ    ‚îÇ TVLA  ‚îÇ
    ‚îÇLeak   ‚îÇ    ‚îÇ Leak  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ          ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   Mitigation:   ‚îÇ
        ‚îÇ  Constant Time  ‚îÇ
        ‚îÇ   Shuffling     ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Propiedades de Nodos
- **Instruction:** id, avg_energy, max_latency, sample_count
- **Pattern:** type (CPA/TVLA), strength, p_value, affected_instr
- **Mitigation:** name, effectiveness, cost, complexity

### Relaciones
- `CORRELATES_WITH(correlation > 0.7)`
- `LEAKS_INFORMATION(cpa > 0.8 OR tvla_p < 0.01)`
- `MITIGATED_BY(severity_before, severity_after)`
- `IMPLEMENTED_IN(instruction, software/hardware)`

---

## üîß CONFIGURACI√ìN RECOMENDADA

### Infrastructure
```yaml
Components:
  - LightRAG: Orchestrador
  - Neo4j: Graph store (relaciones)
  - Milvus: Vector store (b√∫squeda sem√°ntica)
  - InfluxDB: Time-series (hist√≥rico)
  - Redis: Cache (consultas frecuentes)

Deployment:
  Docker Compose con todos los servicios
  Vol√∫menes persistentes para grafo
  Backups diarios de Neo4j
```

### Par√°metros de Tuning
```ini
[RAG]
chunk_size = 512
overlap = 128
top_k = 10
similarity_threshold = 0.7

[Renode]
sampling_period_ns = 50000
buffer_size = 1000
measurements_per_run = 10000

[Security Analysis]
cpa_threshold_critical = 0.9
cpa_threshold_high = 0.7
tvla_threshold_critical = 0.0001
tvla_threshold_high = 0.001
```

---

## ‚úÖ CHECKLIST DE IMPLEMENTACI√ìN

- [ ] Crear `renode_adapter.py`
- [ ] Crear `side_channel_extractor.py`
- [ ] Crear `config_renode_rag.json`
- [ ] Implementar ingesta batch
- [ ] Crear consultas RAG ejemplo
- [ ] Validar correlaciones
- [ ] Tests unitarios
- [ ] Documentaci√≥n API
- [ ] Docker Compose
- [ ] CI/CD pipeline

---

## üìà M√âTRICAS ESPERADAS

| M√©trica | Esperado | Actual |
|---------|----------|--------|
| Entidades/hora | 100+ | - |
| Relaciones/hora | 500+ | - |
| Latencia consulta | < 2s | - |
| Precisi√≥n CPA | > 0.95 | 0.97 |
| TVLA p-value | < 0.001 | 0.0003 |

---

## üöÄ SIGUIENTE PASO

Implementar `renode_adapter.py` como primer componente de integraci√≥n.
